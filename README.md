The research project involved comparing the captions generated by multiple models made by extracting features of images using fine tuned versions of different CNN models line VGG16 and InceptionV3 which are pre-trained on ImageNet and then using different RNN based models like LSTM and GRU to generate captions.
